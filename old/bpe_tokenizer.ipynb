{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a8a0592",
   "metadata": {},
   "source": [
    "#  BPE vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e2ec057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformer import build_transformer\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea73da9",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, BOS, EOS, = 0, 1, 2\n",
    "MICHAEL, JIM, PAM = 3, 4, 5\n",
    "MAX_SRC_LEN = 256 # max tokens for dialogue context\n",
    "MAX_TGT_LEN = 128 # max tokens for Michael's response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68854b8b",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb74ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to read a text file and clean it\n",
    "def read_lines(p):\n",
    "    return [l.strip() for l in open(p, encoding=\"utf-8\").read().splitlines() if l.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6f637",
   "metadata": {},
   "source": [
    "`to_bytes` helper:\n",
    "- Convert a string to a list of byte values (integers 0–255).\n",
    "- Each character becomes its UTF-8 byte representation.\n",
    "- This is how a byte-level tokenizer works — every possible character is just one token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d1954ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helpers: boolean masks where True = keep, False = pad/blocked ---\n",
    "\n",
    "def pad_to(ids, L, pad=PAD):\n",
    "    return ids[:L] + [pad] * max(0, L - len(ids))\n",
    "\n",
    "def enc_pad_mask(x, pad_id=PAD):\n",
    "    \"\"\"(B,S) → (B,1,1,S) True for real tokens\"\"\"\n",
    "    return (x != pad_id).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "def dec_masks(tgt_in, pad_id=PAD):\n",
    "    \"\"\"(B,T) → tgt_pad (B,1,1,T), tgt_causal (1,1,T,T), tgt_mask (B,1,T,T)\"\"\"\n",
    "    B, T = tgt_in.size()\n",
    "    tgt_pad = (tgt_in != pad_id).unsqueeze(1).unsqueeze(2)\n",
    "    tgt_causal = torch.tril(\n",
    "        torch.ones(T, T, dtype=torch.bool, device=tgt_in.device)\n",
    "    ).unsqueeze(0).unsqueeze(1)\n",
    "    tgt_mask = tgt_pad & tgt_causal\n",
    "    return tgt_pad, tgt_causal, tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa42350b",
   "metadata": {},
   "source": [
    "**`pad_to`** (paddling function):\n",
    "- if the list ids (token sequence) is longer than $L$, it will truncate it: `ids[:L]`\n",
    "- if shorter, append enough [pad] tokens to reach length L\n",
    "  \n",
    "**`enc_pad_mask`**:\n",
    "- `x`: input token of shape (batch_size, seq_len)\n",
    "- `(x != pad_id)`: boolean tensor — False when the token is a padding token PAD, else True\n",
    "- `unsqueeze(1).unsqueeze(2)`: add two singleton dimensions(B, 1, 1, S), to match the attention score shape (B, heads, T, S)\n",
    "\n",
    "**`dec_masks`**:\n",
    "- `tgt_in`: decoder input of shape (B, T)\n",
    "- `tgt_pad`: same idea as before, marks non-PAD positions → shape (B,1,1,T)\n",
    "- `tgt_causal`: a lower-triangular matrix of Trues → (1,1,T,T), ensures that token $t$ can only attend $\\le t$ (causal/self-attention mask)\n",
    "- `tgt_mask = tgt_pad & tgt_causal`: combine both → (B,1,T,T), only keeps real tokens in the past or present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135d70ee",
   "metadata": {},
   "source": [
    "## Tokenisation (BPE)\n",
    "\n",
    "https://sebastianraschka.com/blog/2025/bpe-from-scratch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c6cc132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ones'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_lines = read_lines(\"src.txt\")\n",
    "tgt_lines = read_lines(\"tgt.txt\")\n",
    "\n",
    "gpt2_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "gpt2_tokenizer.decode([3392])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f88f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocab as set of byte values + specials\n",
    "vocab = {PAD, BOS, EOS} | set(range(256))\n",
    "vocab_size = max(vocab)+1  # = 257+ (we're reserving 0..2 already)\n",
    "\n",
    "def encode_str(s):\n",
    "    return [BOS] + [b+3 for b in to_bytes(s)] + [EOS]  # shift bytes by +3 to leave 0..2 for specials\n",
    "\n",
    "def decode_ids(ids):\n",
    "    b = [i-3 for i in ids if i>=3]\n",
    "    return bytes(b).decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "# Encode all lines\n",
    "enc_src = [encode_str(s) for s in src_lines]\n",
    "enc_tgt = [encode_str(s) for s in tgt_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec00a60",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6410982",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OfficeSeq2Seq(Dataset):\n",
    "\n",
    "    def __init__(self, enc_src, enc_tgt, max_src: int=MAX_SRC_LEN, max_tgt: int=MAX_TGT_LEN) -> None:\n",
    "        super().__init__()\n",
    "        self.src = enc_src\n",
    "        self.tgt = enc_tgt\n",
    "        self.max_src = max_src\n",
    "        self.max_tgt = max_tgt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "    \n",
    "    def __getitem__(self, i): \n",
    "        s = pad_to(self.src[i], self.max_src)\n",
    "        t = pad_to(self.tgt[i], self.max_tgt)\n",
    "        dec_in = t[:-1] # Shift right for teacher forcing\n",
    "        labels = t[1:]\n",
    "        return torch.tensor(s), torch.tensor(dec_in), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646f5e8",
   "metadata": {},
   "source": [
    "`__len__`: tells PyTorch how many samples are in the dataset\n",
    "\n",
    "`__getitem__`: when DataLoader asks for the i-th item in our dataset:\n",
    "- take the i-th source (self.src[i]) and pad it to max_src\n",
    "- take the i-th target (self.tgt[i]) and pad it to max_tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d76140",
   "metadata": {},
   "source": [
    "**Teacher Forcing & Sequence Shifting**:\n",
    "\n",
    "In seq2seq models (like Transformers), we train the decoder to predict the next token\n",
    "given all previous true tokens, not its own predictions.\n",
    "This is called Teacher Forcing.\n",
    "\n",
    "We prepare the target sequence `t` like this:\n",
    "\n",
    "| Token role | Example | Explanation |\n",
    "|-------------|----------|-------------|\n",
    "| `t` | `[BOS, H, e, l, l, o, EOS]` | the full target sequence |\n",
    "| Decoder input `dec_in` | `[BOS, H, e, l, l, o]` | shifted right (starts with BOS) |\n",
    "| Labels `labels` | `[H, e, l, l, o, EOS]` | shifted left (the \"next\" tokens) |\n",
    "\n",
    "During training, at each time step *t*, the model sees the real previous token (from `dec_in[t-1]`) and learns to predict the next token (`labels[t]`).\n",
    "\n",
    "At inference time, we feed back the model’s *own* predictions instead\n",
    "(one token at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10caed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(enc_src); split = int(0.9*N)\n",
    "train_ds = OfficeSeq2Seq(enc_src[:split], enc_tgt[:split])\n",
    "val_ds   = OfficeSeq2Seq(enc_src[split:],  enc_tgt[split:])\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=32, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9744ce",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "277ffd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idrishouiralami/Documents/projets_code/GPT/transformer.py:254: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  nn.init.xavier_uniform(p)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "vocab_size = 256 + 3  # bytes + specials (PAD,BOS,EOS)\n",
    "\n",
    "model = build_transformer(\n",
    "    src_vocab_size=vocab_size, tgt_vocab_size=vocab_size,\n",
    "    src_seq_len=MAX_SRC_LEN, tgt_seq_len=MAX_TGT_LEN-1,  # decoder sees T-1\n",
    "    d_model=256, N=3, h=4, dropout=0.1, d_ff=1024\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540ac9b",
   "metadata": {},
   "source": [
    "## Loss / Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6c1d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "opt  = AdamW(model.parameters(), lr=3e-4, betas=(0.9,0.95), weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a592a47",
   "metadata": {},
   "source": [
    "## Train / Eval loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfa14405",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# --- main training loop with progress and stats ---\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 49\u001b[0m     tr \u001b[38;5;241m=\u001b[39m run_epoch(\u001b[43mtrain_dl\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m     va \u001b[38;5;241m=\u001b[39m evaluate(val_dl)\n\u001b[1;32m     51\u001b[0m     ppl \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mexp(va)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dl' is not defined"
     ]
    }
   ],
   "source": [
    "# --- train/eval loops with tqdm progress bar ---\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train(train)\n",
    "    total = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    # tqdm bar setup\n",
    "    phase = \"train\" if train else \"val\"\n",
    "    pbar = tqdm(loader, desc=f\"{phase} epoch\", leave=False)\n",
    "    \n",
    "    for src, dec_in, labels in pbar:\n",
    "        src, dec_in, labels = src.to(device), dec_in.to(device), labels.to(device)\n",
    "\n",
    "        # Masks\n",
    "        src_mask = enc_pad_mask(src)\n",
    "        _, _, tgt_mask = dec_masks(dec_in)\n",
    "\n",
    "        # Forward\n",
    "        enc_out = model.encode(src, src_mask)\n",
    "        dec_out = model.decode(enc_out, src_mask, dec_in, tgt_mask)\n",
    "        logits = model.project(dec_out)\n",
    "\n",
    "        loss = crit(logits.reshape(-1, logits.size(-1)), labels.view(-1))\n",
    "\n",
    "        if train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "        total += loss.item()\n",
    "        steps += 1\n",
    "\n",
    "        # update progress bar\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.3f}\"})\n",
    "\n",
    "    pbar.close()\n",
    "    return total / max(1, steps)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    return run_epoch(loader, train=False)\n",
    "\n",
    "\n",
    "# --- main training loop with progress and stats ---\n",
    "for epoch in range(10):\n",
    "    tr = run_epoch(train_dl, True)\n",
    "    va = evaluate(val_dl)\n",
    "    ppl = math.exp(va)\n",
    "    print(f\"epoch {epoch+1:02d} | train {tr:.3f} | val {va:.3f} | ppl {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b421b",
   "metadata": {},
   "source": [
    "**`for src, dec_in, labels in pbar`** batch loop:\n",
    "- `src`: source sequence (the dialogue before Michael speaks)\n",
    "- `dec_in`: decoder input (shifted Michael response)\n",
    "- `labels`: expected next tokens\n",
    "- `src_mask` &  `tgt_mask`: builds proper masks for src & tgt\n",
    "- `enc_out`: encode the src sequence\n",
    "- `dec_out`: decode given src sequence & previous outputs\n",
    "- `logits`: projects to vocab size\n",
    "- `loss`: computes the CrossEntropyLoss\n",
    "- `if train`: then backpropagates the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52d589",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02772770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MICHAEL] Wel, that that t that t that t t thathat t t thathe t t the thathe ath\n"
     ]
    }
   ],
   "source": [
    "def dec_mask_from(dec_in, pad_id=PAD):\n",
    "    # (B,T) -> (B,1,T,T) keep-mask (padding ∧ causal)\n",
    "    B, T = dec_in.size()\n",
    "    tgt_pad = (dec_in != pad_id).unsqueeze(1).unsqueeze(2)               # (B,1,1,T)\n",
    "    tgt_causal = torch.tril(torch.ones(T, T, dtype=torch.bool, device=dec_in.device)).unsqueeze(0).unsqueeze(1)  # (1,1,T,T)\n",
    "    return tgt_pad & tgt_causal\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_reply(context_text, max_new_tokens=80):\n",
    "    model.eval()\n",
    "    # encode & pad the source once\n",
    "    src_ids = pad_to(encode_str(context_text), MAX_SRC_LEN)\n",
    "    src = torch.tensor(src_ids, dtype=torch.long, device=device).unsqueeze(0)   # (1,S)\n",
    "    src_mask = enc_pad_mask(src)                                                # (1,1,1,S)\n",
    "    enc_out = model.encode(src, src_mask)                                       # (1,S,d)\n",
    "\n",
    "    # start decoder with BOS\n",
    "    dec = torch.tensor([[BOS]], dtype=torch.long, device=device)                # (1,1)\n",
    "\n",
    "    # generate until EOS or max_new_tokens reached\n",
    "    while (dec.size(1) - 1) < max_new_tokens:\n",
    "        tgt_mask = dec_mask_from(dec)                                           # (1,1,T,T)\n",
    "        dec_out = model.decode(enc_out, src_mask, dec, tgt_mask)                # (1,T,d)\n",
    "        logits  = model.project(dec_out)                                        # (1,T,V)\n",
    "        next_token = logits[:, -1, :].argmax(dim=-1, keepdim=True)              # greedy → (1,1)\n",
    "        dec = torch.cat([dec, next_token], dim=1)                               # append\n",
    "        if next_token.item() == EOS:\n",
    "            break\n",
    "\n",
    "    return decode_ids(dec[0].tolist())\n",
    "\n",
    "# example\n",
    "print(generate_reply(\"[JIM] Is Dwight the assistant regional manager?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
