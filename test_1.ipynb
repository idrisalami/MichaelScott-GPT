{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e2ac21",
   "metadata": {},
   "source": [
    "# Byte-level Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3365c4a2",
   "metadata": {},
   "source": [
    "### Overview\n",
    "Trains a transformer chatbot to mimic Michael Scott's speaking style using byte-level tokenization - treating each character as a separate token (0-255 byte values).\n",
    "\n",
    "### Key Components\n",
    "- Tokenizer: Custom ByteTokenizer (vocab size: 259 = 256 bytes + 3 special tokens)\n",
    "- Model: Encoder-decoder transformer (d_model=256, 3 layers, 4 heads)\n",
    "- Training: Uses modular Trainer class with train/val split\n",
    "- Generation: Multiple strategies (greedy, balanced, creative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2ec057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/idrishouiralami/Documents/projets_code/GPT')\n",
    "\n",
    "from gpt_tokenizers.byte_level import ByteTokenizer, VocabInfo\n",
    "from utils.transformer import build_transformer\n",
    "from utils.masks import Masks\n",
    "from utils.data_loader import OfficeSeq2Seq, get_local_data\n",
    "from training.train import Trainer, TrainConfig\n",
    "from generation.inference_local_model import MichaelScottBot\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from typing import Tuple, Optional, Dict\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68854b8b",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1918e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = VocabInfo(\n",
    "        pad_id=0, \n",
    "        bos_id=1, \n",
    "        eos_id=2, \n",
    "        shift=3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f56b6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PATH = \"data/src.txt\"\n",
    "TGT_PATH = \"data/tgt.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d443f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SRC_LEN = 256\n",
    "MAX_TGT_LEN = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb921d",
   "metadata": {},
   "source": [
    "## Tokenisation (byte-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635b1aae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SRC_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m src_lines, tgt_lines \u001b[38;5;241m=\u001b[39m get_local_data(\u001b[43mSRC_PATH\u001b[49m, TGT_PATH)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SRC_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "src_lines, tgt_lines = get_local_data(SRC_PATH, TGT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae9e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all lines\n",
    "tok = ByteTokenizer(vocab=vocab)\n",
    "  # SHIFT=3, PAD=0,BOS=1,EOS=2 by default\n",
    "enc_src = tok.encode_batch(src_lines)\n",
    "enc_tgt = tok.encode_batch(tgt_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "700094b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tok.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec00a60",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10caed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(enc_src); split = int(0.9*N)\n",
    "\n",
    "train_ds = OfficeSeq2Seq(enc_src[:split], enc_tgt[:split], MAX_SRC_LEN, MAX_TGT_LEN, pad_id=vocab.pad_id)\n",
    "val_ds   = OfficeSeq2Seq(enc_src[split:],  enc_tgt[split:],  MAX_SRC_LEN, MAX_TGT_LEN, pad_id=vocab.pad_id)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True,  drop_last=True,  pin_memory=False)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=32, shuffle=False, drop_last=False, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9744ce",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ffd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/idrishouiralami/Documents/projets_code/GPT/utils/transformer.py:254: FutureWarning: `nn.init.xavier_uniform` is now deprecated in favor of `nn.init.xavier_uniform_`.\n",
      "  nn.init.xavier_uniform(p)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = build_transformer(\n",
    "    src_vocab_size=vocab_size, tgt_vocab_size=vocab_size,\n",
    "    src_seq_len=MAX_SRC_LEN, tgt_seq_len=MAX_TGT_LEN-1,  # decoder sees T-1\n",
    "    d_model=256, N=3, h=4, dropout=0.1, d_ff=1024\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a592a47",
   "metadata": {},
   "source": [
    "## Train / Eval loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e4c526d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27a464078374cf59322387ba251c6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64210671cf1548f299264b0ec99166c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val epoch:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train 1.812 | val 1.671 | ppl 5.32\n"
     ]
    }
   ],
   "source": [
    "cfg = TrainConfig(pad_id=vocab.pad_id, epochs=1, amp=False)  # set amp=True on CUDA if you want\n",
    "trainer = Trainer(model, device=device, cfg=cfg)      # \"cuda\" / \"cpu\" / \"mps\"\n",
    "history = trainer.fit(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52d589",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ad46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = Masks(pad_id=vocab.pad_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d937fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator with your trained model\n",
    "bot = MichaelScottBot(\n",
    "    model=model,\n",
    "    tokenizer=tok,\n",
    "    masks=masks,\n",
    "    device=device,\n",
    "    config=cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6a6670f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MICHAEL] Oh, well.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60f1546d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MICHAEL] Oh, they.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.balanced(\"[JIM] Hi Michael\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53d19595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MICHAEL] Goder, this.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.creative(\"[JIM] Hi Michael\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcd29e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MICHAEL] Okay..'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom parameters\n",
    "bot.generate(\n",
    "    \"[DWIGHT] I am the best salesman.\",\n",
    "    temperature=0.9,\n",
    "    top_k=80,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
